quizid,text,section,docsrc,docid
q261,What is the technique of keeping frequently used disk data in main memory called? Processing. Caching. Data loading. Memory optimization,iir_4_1,iir,2105
q262,The part of main memory where a block being read or written is stored is known as? Data index. Buffer. Data block. Dictionary,iir_4_1,iir,2105
q263,How are the terms represented in order to make index  index construction more efﬁcient? verbose terms. termIDs. term constants. term coefficients,iir_4_2,iir,2106
q264,What is the advantage of using an external sorting algorithm? Maximizes output efficiency. Minimizes number of random disk seeks during sorting. Enhances sorting. Improves caching,iir_4_2,iir,2106
q265,What is the full form of BSBI? Binary System Based Indexing Algorithm. Bubble Sort Based Indexing Algorithm. Buffer System Based Index. Block Sort Based Indexing Algorithm,iir_4_2,iir,2106
q266,What is a more scalable alternative compared to BSBI for very large collections? Dictionary Sorting. Multi BSBI. Single pass in memory indexing. Sparse Parsing,iir_4_2,iir,2106
q267,What is the difference between BSBI and SPIMI SPIMI adds a posting indirectly to its postings list. SPIMI adds a posting directly to its postings list. Terms are better organized by BSBI. SPIMI is microscopic,iir_4_3,iir,2107
q268,Which is a general architecture for distributed computing? HFFS. DistributedScale. MapReduce,iir_4_4,iir,2108
q269,Which of these directs the process of assigning and reassigning tasks into individual worker nodes? HyperBase. Master Node. Co ordinator . Slave Node,iir_4_4,iir,2108
q270,What are the local intermediate files in the Map Reduce called as? block files. Segment files. local files. Interim files,iir_4_4,iir,2108
q271,What is periodic reconstruction of indexes known as? Periodic Indexing. Data Extension. Index reformation. Dynamic indexing,iir_4_4,iir,2108
q272,What are the 2 types of indexes used in dynamic indexing? Large and Tiny. Main and Secondary. Primary and Secondary. Main and Auxillary,iir_4_5,iir,2109
q273,What is an important consideration for retrieval systems in corporations? Size of data. Security. Fast retrieval,iir_4_6,iir,2110
q274,What is an example of retrieval system used for user authorization? Namelist. Access control lists. Phone directory,iir_4_6,iir,2110
q275,What does rule of 30 state? 30 most common words account for 30% written text.. All documents have 30% verbs.. All documents have a minimum of 30 articles.. 30% words in documents have 50% written text.,iir_5_1,iir,2113
q276,Which technique discards information? Lossless compression. Tiny compression. Zip compression. Lossy compression,iir_5_1,iir,2114
q277,Which law estimates vocabulary size as a function of collection size? Heper Law. Zip Law. Collections law. Heaps Law,iir_5_1,iir,2114
q278,What is the main goal of compressing dictionary? support low query throughput. improve distribution of load. support high query throughput. implement improved indexing,iir_5_2,iir,2116
q279,Why is dictionary compression not suitable always? Small corporations have better methods. Large corporation may have multiterabyte collection with large vocabulary. Large compression may be expensive,iir_5_2,iir,2117
q280,What uses an integral number of bytes to encode a gap? integral encoding. variable byte encoding. invariant transform. variable bitwise code,iir_5_3,iir,2120
q281,What is the simplest bit level code known as? gamma code. unary code. beta code. bit level code,iir_5_3,iir,2121
q282,What determines the coding properties of a discrete probability distribution? absolute value. entropy. index coefficient,iir_5_3,iir,2121
q283,What are the advantages of compressing text? takes less time to be transmitted over a communication link. requires less storage space. less time to search directly,mir_7_4,mir,2124
q284,What are the two approaches to text compression? statistic and dictionary based. probabilistic and term based. probabilistic and statistic. dictionary and term based,mir_7_4,mir,2125
q285,What are the 2 well known statistical coding strategies? Huffman and arithmetic coding. Bitman and Byteman coding. Heap and arithmetic coding,mir_7_4,mir,2125
q286,Which of these are types of compression model semi static. probabilistic. non adaptive,mir_7_4,mir,2126
q287,Which of these scheme uses the idea of replacing strings of characters with a reference to a previous occurrence of the string? non adaptive dictionary scheme. Ziv lempel type adaptive dictionary scheme. Hips compression,mir_7_4,mir,2127
q288,What files are widely used to index large text files? Scalable files. Compressed files. Inverted files. Fast files,mir_7_4,mir,2128
q289,What do successful search techniques for medium size databases use? Btree index. combine online and indexed searching. Library index,mir_8_1,mir,2130
q290,"Inverted files, suffix arrays and signature files are all examples of? data structures. Retrieval models. indexing techniques",mir_8_1,mir,2130
q291,What are the 2 elements of inverted files? grammar and vocabulary. vocabulary and occurences. vocabulary and terms. index and vocabulary,mir_8_2,mir,2131
q292,Why is block addressing used in inverted files? to improve querying. to reduce space requirements. to advance retrieval. to reduce time complexity,mir_8_2,mir,2131
q293,Which of these are steps for search algorithm on an inverted index? manipulation of occurences. retrieval of occurences. vocabulary search,mir_8_2,mir,2131
q294,What are the disadvantages of suffix trees? it varies the index. answers more complex queries. costly construction process,mir_8_3,mir,2135
q295,What is used to overcome the problems of large suffix arrays? super index. supra indices. meta index. random disk access,mir_8_3,mir,2135
q296,Where are set manipulation algorithms used? vector queries. boolean queries. suffix tree. prefix tree,mir_8_3,mir,2136
q297,What does lazy evaluation refer to? Results are delivered beforehand. Results are never delivered but once. Results are delivered only when required,mir_8_4,mir,2137
q298,When is sequential searching used? when no data structure has been built on text. when sequential arrays are introduced. When indices become complex,mir_8_5,mir,2138
q299,Which algorithm involves trying all possible pattern positions in text? Boyer Moore. Brute force. Knuth Morris Pratt,mir_8_5,mir,2139
q300,What is one of the classical solution to approximate string matching? Brute force. Dynamic programming. XOR operation. transformation,mir_8_6,mir,2147
q301,What is the fastest algorithm for low error levels in pattern matching based on? Filtering. Dynamic programming. Parallelism,mir_8_6,mir,2148
q302,How is structural information stored? step wise index. query level . meta index. ad hoc index,mir_8_7,mir,2150
q303,What are the strings that identify structural elements known as? tags. scripts. structural strings. index,mir_8_7,mir,2150
q304,Which of these is an approach to directly searching compressed text? Morse coding. Decoding. Encoding. Huffman coding,mir_8_8,mir,2151
q305,What is true about text compression? it varies the index. Query times are high. it can be done independently of the index,mir_8_8,mir,2153
q306,What are the main trends in indexing and searching textual databases? Searching is getting complex. Text collections are becoming huge. Compression is becoming a star in the field,mir_nan,mir,2155
q307,Which of the following index(es) will help to handle the fields inside a documents? (select as many as appropriate) backbook index. parametric index. metadata index. zone index,iir_6_1,iir,2160
q308,which following statement is NOT true about machine-learned relevance? often a linear function will be learned. some weights will be learned from the examples. it needs some examples with clear indication of relevant or non-relevant. the final score assumes that different zones have the same weight,iir_6_1,iir,2162
q309,What is term frequency? how many times a term appears in the document. how many times a document appears in the collection. how many times a term appears in the index. how many times a document appears in the index,iir_6_2,iir,2164
q310,what is document frequency? how many documents contain the term. how many times a term appears in a document. how many documents in the collection. how many times a term appears in the collection,iir_6_2,iir,2165
q311,"which of the following statement(s) reflect the idea of inverse document frequency? if a term has high inverse document frequency, it has high chance to be a stop word. if a term appears in many documents, it is probably not an important term. document frequency is the same as term frequency. if a term has high document frequency, it is an important term",iir_6_2,iir,2165
q312,"TF-IDF indicates that the higher the value of TF, the lower the final score. the final score is influenced by both TF value and IDF value . the final score is calculated by using TF value to minus IDF value. the lower the value of IDF, the higher the final score",iir_6_2,iir,2166
q313,"look at figure 6.10, which document is the most similar to the query q? all three has the same similarity. d1. d3. d2",iir_6_3,iir,2168
q314,what is true about the query in vector space model? query vector is created based on the vocabulary of the collection index. query's vector only contains query terms for its dimensions. query cannot be represented as a vector . query has the same representation as it in Boolean model,iir_6_3,iir,2169
q315,why we need to consider document length in TF-IDF? short documents if relevant is more useful. short documents tend to have higher TF value. longer documents often contain more relevant information. long documents tend to have higher IDF value,iir_6_4,iir,2175
q316,"what is not true about statistical language model idea? a document is a good match to a query if it has high probability of generating the query. both the relevant documents and the query are from the same language model. a document has high probability if the query terms appear often. similar to inverse document frequency, a document is less likely to be relevant if the query term appear often in it",iir_12_1_1,iir,2177
q317,"formally, which is true about a language model M over an alphabet E? the sum of the probabilities of all words in E can sometimes smaller or larger than 1. if we know the probability of each word in a string being generated by the language model, we can calculate the overall probability of the string being generated by the language model. . some words in E has probabilities but some words do not. if a language model is built based on several documents, then each document will have its own separate alphabet E",iir_12_1_1,iir,2179
q318,what is true about likelihood ratio? the outcomes of the ratio is still probabilities. it helps to overcome the problem that the emission probabilities can be too small. it cannot be used to compare between two language models. its results can alter the ranking of documents,iir_12_1_1,iir,2179
q319,"which one of the following is correct about unigram language model? it considers the context of a word in calculation. it assumes that the probability of a sentence generated from the language model is the multiplied probabilities of individual words. it is the most complicated language model . it can calculate the probability of a document given a language model, but not that of a word given a language model",iir_12_1_2,iir,2180
q320,"which one is NOT true about multinomial distribution? it takes the ""bag of words"" assumption. it depends on preceding context. it is related to unigram language model. it considers the frequency of a word in a document",iir_12_1_3,iir,2181
q321,what is NOT true about query likelihood model? it estimates the probability of a document being generated from a language model. it infers a language model for each document. it ranks the documents according to the probabilities. it estimates the probability of generating the query for each of the language model,iir_12_2_1,iir,2183
q322,what is true about maximum likelihood estimation for the probability of a word being generated from a document? it is related to the total number of words in the document. it does not consider the term frequency. a word appearing in the document can have zero probability. it does not consider document length,iir_12_2_2,iir,2184
q323,"which one is NOT true about smoothing? it generates small probabilities to those words with zero probabilities. after smoothing, the outcome is not probability anymore. it reduce non-zero probabilities. it helps those words that not occur in the document",iir_12_2_2,iir,2184
q324,what is true about the common ways of language model approaches document likelihood considers both document model and query model. calculating the probability of query generated from a document model is called query likelihood model. model comparison approach still generates probabilities. calculating the probability of a document generated from the query model is called query likelihood model,iir_12_3,iir,2186
q325,What does a ground truth judgment of relevance mean? documents have no classification. true scores. document that contains only true information. documents have binary classification as either relevant or non relevant,iir_8_1,iir,2190
q326,Which of the following are standard test collections? datagov. Cranfield. CLEF. TREC,iir_8_2,iir,2191
q327,Which one of the following is the most used news collections for information retrieval? gov2. Usenet. Reuters. TREC,iir_8_2,iir,2191
q328,Which are the two most basic measures for information retrieval effectiveness? Quality. Recall. Precision. Index,iir_8_3,iir,2192
q329,What is recall? fraction of accurate documents. Fraction of relevant documents that are retrieved. sum of relevant and non relevant documents. Fraction of retrieved documents that are relevant,iir_8_3,iir,2192
q330,What is a measure that trades off between precision and recall? F measure or weighted harmonic mean. Mean Reciprocal Rank. M measure or mode. Accuracy,iir_8_3,iir,2192
q331,What is true about Mean Average Precision(MAP) for a test collection? it is an interpolated precision. single figure measure of quality across recall levels. it is the arithmetic mean of average precision values for individual information needs,iir_8_4,iir,2193
q332,What is pooling? joining results of different queries. non relevance assesment. relevance assessed from a subset of collection formed from top k documents. creating pools for individual queries,iir_8_5,iir,2194
q333,What is an example of marginal relevance? documents with other languges. the first page. TREC documents. duplicate results on world wide web,iir_8_5,iir,2194
q334,Which of the following are benchmarks to rate an IR system beyond retrieval quality? How expressive is its query language?. How large is the data collection. How fast does it index?. How fast does it search,iir_8_6,iir,2196
q335,How is user satisfaction measured by web search engines? A/B testing. clickthrough log analysis. B/A testing,iir_8_6,iir,2196
q336,What is associated with results snippets? click analysis. index number. keyword in context. text summarization,iir_8_7,iir,2200
q337,Which one is true about relevance feedback? ask search specialist to provide feedback. involve user in the retrieval process to improve the final result set. Teach users to issue good queries. understand user history,iir_9_1,iir,2203
q338,What is NOT true about relevance feedback? involves user interaction. system computes better representation of information need. precision is not improved. may include one or more iterations,iir_9_1,iir,2204
q339,Which of the following are cases in which relevance feedback alone is not sufficient? cross language information retrieval. query expansion. misspellings. order of results,iir_9_1,iir,2205
q340,Which of the following automates the manual part of relevance feedback? automatic relevance feedback. indirect relevance feedback. pseudo relevance feedback. direct relevance feedback,iir_9_1,iir,2209
q341,Which is true about the search term suggestion in an IR system? History search queries from users themselves. Search queries from other users. thesaurus or controlled vocabulary,iir_9_2,iir,2213
q342,What is true about query expansion? it is more likely to increase recall. it is effective in learning new terms. it is more likely to increase recall. it is not user friendly,iir_9_2,iir,2215
q343,How can user interfaces for IR systems help users? Help formulate their queries. Keep tracking users' search progress. Understand their search results,mir_10_1,mir,2218
q344,Which of the following are design principles used for IR systems? Provide alternative interfaces for novice and expert users. Reduce working memory load. Offer informative feedback,mir_10_2,mir,2220
q345,Which of the following are the main information visualization techniques used for Information Access? Painting. Panning and Zooming. Brushing and Linking,mir_10_2,mir,2221
q346,What is Focus-plus-context in information visualization? Refers to scanning sideways across a screen. Make one portion of the view larger and simultaneously shrink the other objects. Less details are visible about an item,mir_10_2,mir,2221
q347,"What is TRUE about models of interaction in IR systems? Users' information needs are satisfied by a series of selections and bits of information found along the way during search. Users do not learn during the search process. Users' information needs are always satisfied by a single, final retrieved set of documents",mir_10_3,mir,2224
q348,Which of the following are examples of Non Search parts of the Information Access Process? Aggregating information. Making comparisons. Finding Trends,mir_10_3,mir,2225
q349,Which of the following are types of Starting Points for search interfaces? Tables. Lists. Automated Source Selection. Paragraph of text,mir_10_4,mir,2227
q350,"What is TRUE about ""overviews"" in search interfaces? It helps users select or eliminate sources from consideration. It can show the topic domains represented within the collections. It provides a very detailed summary",mir_10_4,mir,2229
q351,"What is ""retrieval by reformulation"" in search interfaces? Help users choose best results. Help users start their search with an example of interaction with the system. Repeated retrieval of information. Help users start their search with no interaction",mir_10_4,mir,2230
q352,What is the TRUE about pure Boolean systems? They do not rank the retrieved documents according to their degree of match to the query. In the pure Boolean framework a document either satisfied the query or not. They match the retrieved documents according to their degree of match to the query,mir_10_5,mir,2233
q353,"What is a faceted query? A type of query specification indicating that user's query always belongs to  a single topic. A type of query that is inferior to boolean queries. A type of query specification indicating that user's query is divided into topics, each of which should be present in the retrieved documents. A type of query specification that minimizes the result set",mir_10_5,mir,2235
q354,"What is the disadvantage of enclosing query terms in quotation marks, in search engines? They retrieve non relevant documents. They retrieve rare documents. They may miss many relevant documents as they require exact match of phrases",mir_10_5,mir,2237
q355,"What kind of information is included in a ""document surrogate"" ? Lenghth of the article. Date and source of the document. Relevance score or percentage",mir_10_6,mir,2240
q356,What is the full form of KWIC? Key Word In Context. Key Word In Contrast. Key Word In Category,mir_10_6,mir,2242
q357,Which of the following is a solution to solve the problem of displaying documents in terms of multiple attributes? VIBE. Lattices. InfoCrystal. Lyberworld,mir_10_6,mir,2242
q358,How can hyperlink information be useful for IR systems? By navigation to search history. By filtering results in chronological order. By providing context for retrieval results,mir_10_6,mir,2245
q359,Which of the following is a proven effective technique for query reformulation? Relevance Feedback. Number of retrieved documents. Query Score,mir_10_7,mir,2247
q360,Which of the following are examples of fetching information in the background? Semi automated assistants. Letizia. Syskill and Webert,mir_10_7,mir,2250
q361,Pseudo Relevance Feedback mechanism is more likely to be effective in which of the following cases? Query statement is short. Query statement contains only a single term. Query statement is long and precise,mir_10_7,mir,2252
q362,How can we solve the problem of empty result sets due to spelling errors? By using a spell checking function that suggests alternatives for query terms. By tutorials to issue good queries. By suggesting thesaurus terms associated with the query terms,mir_10_8,mir,2254
q363,Which of the following are examples of retaining search history? Allow users to annotate choices made. Allow users to issue queries repeatedly. Allow users to save portions of a search session,mir_10_8,mir,2258
q364,"Early attempts at making web information ""discoverable"" fell into two broad categories such as? Non index based retrieval. Full-Text index search engines. Taxonomies populated with web pages in categories. Half-Text index search engines",iir_19_1,iir,2263
q365,What turned out to be the biggest challenge for web search engines in their quest to index and retrieve content? Decentralized content publishing with no central control of authorship. Centralized content publishing with control of authorship. Presence of large amounts of text,iir_19_2,iir,2264
q366,What are static web pages? Web pages that have images. Web pages whose content varies dynamically. Web pages whose content does not vary from one request for that page to the next,iir_19_2,iir,2264
q367,Manipulation of web page content for the purpose of appearing high up in search results is an example of? Spamming. Linking. Fast indexing,iir_19_2_2,iir,2266
q368,"What is TRUE about cloaking used by spammers? If the request comes from a search engine crawler, serve misleading content. Spammers include their identity. If the request does not come from  a search engine crawler, serve spam",iir_19_2_2,iir,2266
q369,"The method of pricing advertisements based on the number of times it is displayed during search, is known as? Pricing based on cost per click. Pricing based on impressions. Pricing  based on cost per mil",iir_19_3,iir,2267
q370,What is Search Engine Marketing(SEM)? Performing link analysis to promote products. Performing click spam for marketing. Profession for advertisers to allocate marketing campaign budgets based on ranking  done by search engines,iir_19_3,iir,2267
q371,Search result returning the home page of Lufthansa Airlines that the user has in mind is an example of? Navigational Queries. Informational Queries. Transactional Queries,iir_19_4,iir,2268
q372,What are examples of transactional queries? Downloading a file. Purchasing a product. Making a reservation,iir_19_4_1,iir,2269
q373,Which of the following is a classical estimation technique used to compare and estimate index size of two search engines? Capture-Recapture method. Index manipulation method. Capture-Capture method,iir_19_5,iir,2270
q374,What are some of the sampling approaches used in index estimation? Random IP addresses. Random searches. Random walks,iir_19_5,iir,2270
q375,"What is the phenomenon of ""near duplication"" on web? The contents of one web page complements the contents of another web page. The contents of several web page belong to same topic.. The contents of one web page is exactly identical to an other web page. The contents of one web page are identical to those of another except for a few characters",iir_19_6,iir,2271
q376,Which of the following is a technique to solve the problem of detecting near-duplicate web pages? Duplication avoidance. Shingling. Graph algorithms,iir_19_6,iir,2271
q377,Which of the following are techniques used for link analysis on the web? Advanced Link Analysis. PageRank. Neighbourhood Link Analysis. HITS,iir_21,iir,2273
q378,What is TRUE about anchor text in web search engines? Anchor text is used only for highlighting important terms in a document. The anchor text terms can be included as terms under which to index the target web page. Anchor text generates multiple links to the same page,iir_21_1_1,iir,2275
q379,What is NOT TRUE about PageRank? PageRank is a numerical score between 0 and 1. PageRank enables least visited pages to appear in search results. Frequently visisted pages are more important. PageRank of a node will depend on the link structure of the web graph,iir_21_2,iir,2276
q380,Which of the following is a process that occurs in series of time steps in each of which a random choice is made? Markov chain. Timestep process. Probability states,iir_21_2_1,iir,2277
q381,What happens when a user teleports to a random web page chosen non uniformly? PageRank values get increased for the new pages. PageRank values are never affected. We are able to derive PageRank values tailored to particular interests or topics,iir_21_2_3,iir,2279
q382,What is a personalized PageRank? Score computed for a particular user who is known to have a mixture of interests from multiple topics. Score computed for multiple users who share similar interests. Score computed for a particular user who is known to have just a single interest,iir_21_2_3,iir,2279
q383,What is TRUE about hub pages and authorities? A good authority points to many hub pages. A good hub page is one that points to many good authorities. Authorities and hub pages are not associated to each other,iir_21_3,iir,2280
q384,What is the full form of HITS? High Interval Text Search. Hyper Induced Text Search. Hyperlink Induced Text Search. Hyperlink Induced Topic Search,iir_21_3,iir,2280
q385,"What is TRUE about ""standing query""? It is periodically executed on a collection that never adds new documents. It is periodically executed on a collection to which new documents are added over time. It is executed exactly once on a collection to which new documents are added over time",iir_13,iir,2310
q386,The automatic classification of a movie or product review as positive or negative is known as? Sentiment detection. Vertical search engines. Spam detection,iir_13,iir,2310
q387,Learning a classifer in text classification that maps documents to classes or categories using a learning method or learning algorithm is known as? Unsupervised learning. Document classification. Supervised learning,iir_13_1,iir,2311
q388,What is TRUE about Naïve Bayes text classification? It is also known as multinomial NB model. It is a probabilistic learning method. The goal is to find the best class for the document,iir_13_2,iir,2312
q389,How does multinomial unigram language model differ from multinomial NB model? Classes c take the role of documents in language modelling. Document d takes the role of query in language modelling. Documents and classes are both always identical,iir_13_2,iir,2313
q390,Which of the following is TRUE about Bernoulli model? It uses binary occurrence information when classifying a test document ignoring the number of occurences. It estimates P(t/c) as the fraction of documents of class c that contain term t. It models the absence of terms explicitly,iir_13_3,iir,2314
q391,The gradual change over time of the concept underlying a class like US president from Bill Clinton to George Bush is known as? Concept variation. NB classification estimation. Concept drift,iir_13_4,iir,2315
q392,What purposes does feature selection serve? It increases classification accuracy. It decreases vocabulary size and makes training and applying classifier more efficient. It increases noise features,iir_13_5,iir,2317
q393,What is overfitting? Correct generalization from an accidental property of the training set. Incorrect generalization from an accidental property of the training set. Fitting data with zero noise features,iir_13_5,iir,2317
q394,Which of the following are types of feature selection methods? Chi square feature selection. Mutual information. Frequency-based feature selection,iir_13_5,iir,2318
q395,What is contiguity hypothesis used in vector space classification? Documents in the same class form a contiguous region and regions of different classes overlap. Documents in different classes form a contiguous region. Documents in the same class form a contiguous region and regions of different classes do not overlap,iir_14,iir,2325
q396,What is TRUE about document vectors? They are length normalized unit vectors that point to the surface of a hypersphere. They are usually non normalized vectors. They play a minor role in vector space classification,iir_14_1,iir,2326
q397,What is TRUE about Rocchio classification? It is one of the best known ways of computing good class boundaries. It uses a probabilistic model for classification. It uses centroid to define boundaries,iir_14_2,iir,2327
q398,"How is K nearest neighbour classification different from that of Rocchio's? Decision boundaries in KNN are non concatenated segments. KNN classification determines the decision boundary locally. In KNN classification, each document is assigned to random class of neighbours",iir_14_3,iir,2328
q399,What is a noise document? A particular document that is not included in the training set misleads the learning method . A document that uses noise features. A document when included in the training set misleads the learning method and increases classification error,iir_14_4,iir,2330
q400,Which of the following is a non linear classifier? Naïve Bayes classifer. Rocchio classifier. k Nearest Neighbour classifier,iir_14_4,iir,2330
q401,What is the classification for classes that are not mutually exclusive known as? Any-of classification. Multivalue classification. Multilabel classification,iir_14_5,iir,2331
q402,What is TRUE about single label classification? The classes are mutually exclusive. Each document must belong to exactly one of the classes. They are also known as any-of classification,iir_14_5,iir,2331
q403,What does bias variance trade off explain about learning methods used in statistical text classification? Non linear classifiers are always more powerful than linear classifiers. There is no universally optimal learning method. There exists linear classifer with zero classification error,iir_14_6,iir,2332
q404,What does variance measure in classifiers? It measures how inconsistent the decisions are. It measures similarity of prediction among classifiers. It measures whether the decisions are correct or incorrect,iir_14_6,iir,2332
q405,What is TRUE about clustering algorithms? The goal of clustering algorithms is to create clusters that are coherent externally. Documents in one cluster should be as dissimilar as possible from documents in other cluster. Documents within a cluster should be as similar as possible,iir_16,iir,2335
q406,Which of the following is NOT TRUE about clustering algorithm? It is a form of unsupervised learning. It is a form of supervised learning. Distance is a key input to clustering algorithms,iir_16,iir,2335
q407,Which of the following are applications of clustering in Information Retrieval? Search result clustering. Language Modelling. Scatter-Gather,iir_16_1,iir,2336
q408,What is the benefit of using Collection-Clustering? Effective information presentation for exploratory browsing. Increased recall. Increased precision,iir_16_1,iir,2336
q409,What is partitional clustering? It refers to a case of both exhaustive and non exhaustive clusters. It refers to a clustering where each document belongs to exactly one cluster. It refers to a clustering where each document belongs to multiple clusters,iir_16_2,iir,2337
q410,What is cardinality of a clustering? It refers to the number of clusters in a clustering. It refers to the number of initial points within a single cluster. It is a combination of partial and complete clustering,iir_16_2,iir,2338
q411,What is TRUE about the internal criterion for the quality of a clustering? Measure of time taken to find answer is large. The goal is to attain low inter cluster similarity. The goal is to attain high intra cluster similarity,iir_16_3,iir,2339
q412,What does external criteria for the quality of clustering evaluate? It measures only the time taken to fetch results. It evaluates cluster dissimilarities. It evaluates how well the clustering matches standard cases produced by human judges,iir_16_3,iir,2339
q413,Which of the following are external criteria of clustering quality? F measure. Rand index. Purity,iir_16_3,iir,2339
q414,What is the objective of the k means clustering algorithm? To assign documents to clusters on iterations. To maximize the average squared euclidean distance of the documents from their cluster centroids. To minimize the average squared euclidean distance of the documents from their cluster centroids,iir_16_4,iir,2340
q415,What is an outlier? Documents that are far from any other document and therefore do not fit well into any cluster. A cluster with multiple documents. A cluster with only one document,iir_16_4,iir,2340
q416,"Which of the following is TRUE about hierarchical clustering? It has high efficiency. It requires us to pre specify the number of clusters. The time complexity is more likely quadratic. It outputs a hierarchy, a structure that is more informative compared to results of flat clustering",iir_17,iir,2345
q417,Which of the following is TRUE about Hierarchical Agglomerative Clustering? It is a top-down approach. It proceeds by splitting clusters recursively until individual documents are reached. It is a bottum-up approach. It treats each document as a singleton cluster at the outset and successively merges pairs into a single cluster with all documents,iir_17_1,iir,2346
q418,What is single linkage clustering? The similarity of two clusters is the similarity of their most similar members. The similarity of two clusters is the similarity of none of the members. The similarity of two clusters is the similarity of their most dissimilar members,iir_17_2,iir,2347
q419,Which of the following is TRUE about complete link clustering? This method is local. The complete link merge criterion is non local. The similarity of two clusters is the similarity of their most dissimilar members,iir_17_2,iir,2347
q420,How does Group-Average Agglomerative Clustering (GAAC) evaluate  cluster quality? It evaluates cluster quality based on SOME of the similarities between documents. It evaluates cluster quality based on ALL dissimilarities between documents. It evaluates cluster quality based on ALL similarities between documents,iir_17_3,iir,2349
q421,Which of the following is TRUE about centroid clustering? The similarity of two clusters is defined as the similarity of their centroids. The number of documents involved in clustering is very less. The similarity of two clusters is defined as the similarity of their documents,iir_17_4,iir,2350
q422,Which of the following HAC algorithms is the best choice for most applications? Centroid. Single-link. Group-average. Complete-link,iir_17_5,iir,2351
q423,What is TRUE about top-down clustering? It is conceptually more complex than bottom up clustering algorithm. It is also known as divisive clustering. They run much faster than HAC algorithms,iir_17_6,iir,2352
q424,"What is differential cluster labelling? It computes a label that solely depends on the cluster itself, not on other clusters. It selects cluster labels by comparing the distribution of terms in one cluster with that of the other clusters. It labels cluster and may not involve feature selection",iir_17_7,iir,2353
q425,"What is cluster-internal labelling? It computes a label that solely depends on the cluster itself, not on other clusters. It selects cluster labels by comparing the distribution of terms in one cluster with that of the other clusters. It labels cluster and may not involve feature selection",iir_17_7,iir,2353
q426,Which of the following statement(s) is(are) TRUE of the Finding Out About(FOA) activity? Relevance feedback from the asker is important for the assessment of the retrieval.. FOA requires users to form their questions clearly reflecting their information need.. FOA requires the search engine to deliver the right answer in the first delivery.. FOA process involves two phrases: asking a question and constructing an answer.. The search engine should be able to identify one or more of the “canned” passages of text and present them to the users.,foa_1_1,foa,2358
q427,"Which of the following statement(s) is(are) TRUE of the field of information retrieval(IR)? The fundamental operation performed by a search engine is to create good indexes for documents.. IR has borrowed from Library Science and computational linguistics.. Information retrieval is a well-studied problem in computer science for FOA, and FOA is a broader characterization of the cognitive process than IR.",foa_1_1,foa,2359
q428,What are the core requirements for Web search engines? Producing as many results as possible to search queries.. Achieving subsecond response times.. Ranking pages by their expected relevance to a query considering varied features.. Producing accurate results to short search queries.,ies_1_1,ies,2362
q429,"What kind of information can we consider for IR systems built on the desktop, enterprise, or digital library level? File versioning.. File formats and creation times.. Structural features of materials.",ies_1_1,ies,2363
q430,"Which of the following problems are covered by the field of information retrieval? Comparing newly discovered documents to a fixed set of queries and identifying those that match a given query closely enough to be of possible interest to the users.. Extracting key paragraphs, sentences, or phrases to describe document content.. Sorting documents into groups based on patterns.. Identifying named entities and combine this information into structured record.",ies_1_1,ies,2364
q431,Which of the following statement(s) is(are) TRUE of the basic IR system architecture? A query consists of a small number of words.. Search engine maintains inverted indexes providing a mapping from a document to its terms.. Complex Boolean and pattern matching operators could be used in queries.,ies_1_2,ies,2366
q432,"Which of the following definition(s) is(are) correct for documents, elements or snippets? A document is any self-contained unit that can be returned to the user as a search result.. Snippets are predefined components returned from larger objects.. Elements are arbitrary text passages or video segments returned from larger objects.",ies_1_2,ies,2367
q433,"Which of the following aspects are usually considered for evaluating IR systems? Efficiency, including response time and storage space.. Novelty of a document.. Coverage of the information related to the need.. Relevance of a document measured by probability of relevance.",ies_1_2,ies,2368
q434,Which of the following topics are included in the scope of IR? Developing efficient ranking algorithms to search for useful documents.. Data visualization.. Building up efficient indexes.. Text classification.,mir2_1_1,mir2,2370
q435,"Which of the following statement(s) is(are) TRUE of the early developments of IR? Early developments in IR date back to research efforts conducted in the 50’.. Man has started organizing information since more than 5,000 years ago.. Indexes are specialized data structures for fast search, which are at the core of every modern information retrieval system.. Nowadays, we still rely library and information science researchers to create large indexes manually.",mir2_1_1,mir2,2371
q436,Which of the following statement(s) is(are) TRUE of the IR problems? Relevance is always objective and stable across contexts.. To form good user queries is always of central importance in IR.. The primary goal of an IR system is to retrieve as many documents as possible according to a user query.,mir2_1_2,mir2,2374
q437,"What are the differences between searching and browsing? A user is searching when he or she can specify a set of words in order to convey the information need.. The task of browsing can be considered as an exploratory searching task.. A user who browses has an interest that is either poorly defined or inherently broad, such that the query to specify is unclear.",mir2_1_2,mir2,2375
q438,What are the differences between information retrieval and data retrieval? An IR system can retrieve objects that contain small errors.. An IR system primarily solves the problem of retrieving information about a subject or topic.. A data retrieval system should return documents containing the keywords or synonyms of the keywords in the query.. An IR system deals with natural language text which is well structured.. Data retrieval can always satisfy the user information need.,mir2_1_2,mir2,2376
q439,Which of the following components are included in the software architecture of the IR system? A query parsing and expanding module expanding a user query to a system query.. A web crawler collecting documents.. An indexer generating inverted indexes for words.. A ranking module identifying the relevant documents. A central repository storing the document collection.,mir2_1_3,mir2,2378
